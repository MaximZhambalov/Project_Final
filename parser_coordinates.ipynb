{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Парсинг геоданных\n",
    "\n",
    "Парсить будем этот сайт - [geocode.maps.co](https://geocode.maps.co/). Возьмем очищенные данные (признаки ***street***, ***state*** и ***zipcode***):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данные для парсинга - это оригинальная таблица без дубликатов и пропусков c тремя столбцами - улица, штат и почтовый индекс\n",
    "# города не очень хорошо подходят, почему-то этот сервис гораздо хуже работает\n",
    "\n",
    "data_to_parse = pd.read_csv('data/data_to_parse.csv')\n",
    "# data_to_parse['location'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314000 locations parsed and saved.\n",
      "315000 locations parsed and saved.\n",
      "316000 locations parsed and saved.\n",
      "317000 locations parsed and saved.\n",
      "318000 locations parsed and saved.\n",
      "319000 locations parsed and saved.\n",
      "320000 locations parsed and saved.\n",
      "321000 locations parsed and saved.\n",
      "322000 locations parsed and saved.\n",
      "323000 locations parsed and saved.\n",
      "324000 locations parsed and saved.\n",
      "325000 locations parsed and saved.\n",
      "326000 locations parsed and saved.\n",
      "327000 locations parsed and saved.\n",
      "328000 locations parsed and saved.\n",
      "329000 locations parsed and saved.\n",
      "330000 locations parsed and saved.\n",
      "331000 locations parsed and saved.\n",
      "332000 locations parsed and saved.\n",
      "333000 locations parsed and saved.\n",
      "334000 locations parsed and saved.\n",
      "335000 locations parsed and saved.\n",
      "336000 locations parsed and saved.\n",
      "337000 locations parsed and saved.\n",
      "338000 locations parsed and saved.\n",
      "339000 locations parsed and saved.\n",
      "340000 locations parsed and saved.\n",
      "341000 locations parsed and saved.\n",
      "342000 locations parsed and saved.\n",
      "343000 locations parsed and saved.\n",
      "344000 locations parsed and saved.\n",
      "Location 344930 parsed...\r"
     ]
    }
   ],
   "source": [
    "for i in range(0, data_to_parse.shape[0]):\n",
    "    street = data_to_parse['street'][i]\n",
    "    # city = data_to_parse['city'][i]\n",
    "    state = data_to_parse['state'][i]\n",
    "    zipcode = data_to_parse['zipcode'][i]\n",
    "\n",
    "    street = street.replace(' ', '+')\n",
    "    # city = city.replace(' ', '+')\n",
    "\n",
    "    api_url = f'https://geocode.maps.co/search?street={street}&state={state}&postalcode={zipcode}&country=US'\n",
    "    response = requests.get(api_url)\n",
    "    while response.status_code != 200:\n",
    "        time.sleep(1)\n",
    "        response = requests.get(api_url)\n",
    "    \n",
    "    data_to_parse.location.iloc[i] = response.json()\n",
    "\n",
    "    print(f'Location {i} parsed...', end='\\r')\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # пишем в файл каждые 1000 запросов\n",
    "    if not i % 1000:\n",
    "        data_to_parse.to_csv(f'data/data_parsed_{i}.csv')\n",
    "        print(f'{i} locations parsed and saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_parse.to_csv('data/data_parsed_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь по сути то же самое что и в 1-м парсинге, только тут адреса скорректированы - убраны номера квартир и прочая ненужная информация\n",
    "\n",
    "# data_to_parse = pd.read_csv('data/data_to_parse_address_correct.csv')\n",
    "# data_to_parse['location'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43000 locations parsed and saved......................\n",
      "44000 locations parsed and saved......................\n",
      "45000 locations parsed and saved......................\n",
      "46000 locations parsed and saved......................\n",
      "47000 locations parsed and saved......................\n",
      "48000 locations parsed and saved......................\n",
      "49000 locations parsed and saved......................\n",
      "50000 locations parsed and saved......................\n",
      "51000 locations parsed and saved......................\n",
      "Location 51081 parsed. Code=200.\r"
     ]
    }
   ],
   "source": [
    "for i in range(42001, data_to_parse.shape[0]):\n",
    "    street = data_to_parse['street_new'][i]\n",
    "    # city = data_to_parse['city'][i]\n",
    "    state = data_to_parse['state'][i]\n",
    "    zipcode = data_to_parse['zipcode'][i]\n",
    "\n",
    "    street = street.replace(' ', '+')\n",
    "    # city = city.replace(' ', '+')\n",
    "    if data_to_parse.street_new.iloc[i] != 'no_address':\n",
    "        api_url = f'https://geocode.maps.co/search?street={street}&state={state}&postalcode={zipcode}&country=US'\n",
    "        response = requests.get(api_url)\n",
    "        j = 0.5\n",
    "        while (response.status_code != 200) & (j <= 1.5):\n",
    "            print(f'Code={response.status_code}. Wait for {j * 2:.2f} sec...........................', end='\\r')\n",
    "            time.sleep(j * 2)\n",
    "            j += 0.25\n",
    "            response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            data_to_parse.location.iloc[i] = response.json()\n",
    "        else:\n",
    "            data_to_parse.location.iloc[i] = 'timeout'\n",
    "        print(f'Location {i} parsed. Code={response.status_code}.', end='\\r')\n",
    "        time.sleep(0.75)\n",
    "    else:\n",
    "        data_to_parse.location.iloc[i] = '[]'\n",
    "    \n",
    "    # пишем в файл каждые 1000 запросов\n",
    "    if not i % 1000:\n",
    "        data_to_parse.to_csv(f'data/data_parsed_{i}.csv')\n",
    "        print(f'{i} locations parsed and saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_parse.to_csv(f'data/data_parsed_{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, этот сервис выдаёт несколько местоположений и зачастую самое значимое оказывается неверным, поэтому эту информацию мы не будем использовать. Данные сохранены в файле **data_local_info.csv**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
